# run_funasr_eval.py
import json
from pathlib import Path
from jiwer import cer, wer
from funasr import AutoModel
import torch
import os

# å‡è®¾ utils.text_norm å­˜åœ¨ï¼›è‹¥ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿ text_normalize å‡½æ•°å®šä¹‰åœ¨æ­¤
try:
    from utils.text_norm import text_normalize
except ImportError:
    # å¦‚æœæ²¡æœ‰ utils/text_norm.pyï¼Œä½¿ç”¨ç®€å• normalize
    import unicodedata
    import re

    def text_normalize(text: str) -> str:
        """Simple text normalization: NFKC + lower + remove punctuation + collapse whitespace"""
        if not isinstance(text, str):
            return ""
        text = unicodedata.normalize("NFKC", text)
        text = text.lower()
        # Remove all punctuation and non-alphanumeric (keep Chinese, English, digits)
        text = re.sub(r"[^\u4e00-\u9fa5a-z0-9]", " ", text)
        text = re.sub(r"\s+", " ", text).strip()
        return text


import jieba


def tokenize_for_wer(text: str) -> str:
    words = jieba.lcut(text)
    words = [word.strip() for word in words if word.strip()]
    return " ".join(words)


def compute_per_utt_cer_wer(ref: str, hyp: str) -> tuple[float, float]:
    try:
        c = cer(ref, hyp)
    except Exception:
        c = 1.0
    try:
        w = wer(ref, hyp)
    except Exception:
        w = 1.0
    return c, w


def main():
    # === è·¯å¾„é…ç½® ===
    BASE_DIR = Path("/calc/users/cisri_shzh_gpu/users/lmy/asr/ASR_GT_pipline")
    data_root = BASE_DIR / "data"
    output_dir = BASE_DIR / "outputs"
    output_dir.mkdir(exist_ok=True)

    dev_dir = data_root / "dev"
    MODEL_LOCAL_PATH = str(BASE_DIR / "FunAudioLLM/Fun-ASR-Nano-2512")  # æœ¬åœ°æ¨¡å‹è·¯å¾„

    # === åŠ è½½ GT ===
    gt_map = {}
    with open(dev_dir / "gt.jsonl", "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                item = json.loads(line)
                gt_map[item["utt_id"]] = item["text_gt"]

    # === åŠ è½½ FunASR æ¨¡å‹ï¼ˆæœ¬åœ°è·¯å¾„ï¼‰===
    print(f"Loading FunASR model from: {MODEL_LOCAL_PATH}")
    if not os.path.exists(MODEL_LOCAL_PATH):
        raise FileNotFoundError(f"Model path not found: {MODEL_LOCAL_PATH}")

    model = AutoModel(
        model=MODEL_LOCAL_PATH,
        trust_remote_code=True,  # å¿…é¡»ä¸º True ä»¥åŠ è½½ model.py
        device="cuda:0" if torch.cuda.is_available() else "cpu",
        disable_update=True,  # å…³é—­ç‰ˆæœ¬æ£€æŸ¥
        remote_code="/calc/users/cisri_shzh_gpu/users/lmy/asr/ASR_GT_pipline/Fun-ASR/model.py",
    )
    print("âœ… FunASR model loaded successfully.")

    # === åˆå§‹åŒ–ç»“æœå®¹å™¨ ===
    per_utt_list = []
    refs_cer_all = []
    hyps_cer_all = []
    refs_wer_all = []
    hyps_wer_all = []

    # === éå† dev/meta.jsonl ===
    with open(dev_dir / "meta.jsonl", "r", encoding="utf-8") as f_meta:
        for line in f_meta:
            if not line.strip():
                continue
            meta_item = json.loads(line)
            utt_id = meta_item["utt_id"]
            if utt_id not in gt_map:
                continue

            wav_path = dev_dir / meta_item["audio_path"]
            if not wav_path.exists():
                print(f"âš ï¸ Audio not found: {wav_path}")
                continue

            ref_raw = gt_map[utt_id]

            # === ASR æ¨ç† ===
            try:
                res = model.generate(
                    input=str(wav_path),
                    batch_size=1,
                    language="zh",  # æ³¨æ„ï¼šæœ¬åœ°æ¨¡å‹é€šå¸¸ç”¨ "zh" è€Œé "ä¸­æ–‡"
                    itn=True,  # å¯ç”¨é€†æ–‡æœ¬å½’ä¸€åŒ–
                )
                hyp_raw = res[0]["text"] if res else ""
            except Exception as e:
                print(f"âŒ ASR failed on {utt_id}: {e}")
                hyp_raw = ""

            # === æ–‡æœ¬æ ‡å‡†åŒ– ===
            ref_cer = text_normalize(ref_raw)
            hyp_cer = text_normalize(hyp_raw)
            if not ref_cer:
                continue

            ref_wer = tokenize_for_wer(ref_cer)
            hyp_wer = tokenize_for_wer(hyp_cer)

            # === è®¡ç®—æŒ‡æ ‡ ===
            utt_cer, _ = compute_per_utt_cer_wer(ref_cer, hyp_cer)
            _, utt_wer = compute_per_utt_cer_wer(ref_wer, hyp_wer)

            # === ä¿å­˜ç»“æœ ===
            per_utt_list.append(
                {
                    "utt_id": utt_id,
                    "ref_raw": ref_raw,
                    "hyp_fun_asr": hyp_raw,
                    "ref_cer": ref_cer,
                    "hyp_cer": hyp_cer,
                    "ref_wer": ref_wer,
                    "hyp_wer": hyp_wer,
                    "cer": round(utt_cer, 4),
                    "wer": round(utt_wer, 4),
                }
            )

            refs_cer_all.append(ref_cer)
            hyps_cer_all.append(hyp_cer)
            refs_wer_all.append(ref_wer)
            hyps_wer_all.append(hyp_wer)

    # === è®¡ç®—æ•´ä½“æŒ‡æ ‡ ===
    overall_cer = cer(refs_cer_all, hyps_cer_all)
    overall_wer = wer(refs_wer_all, hyps_wer_all)

    # === ä¿å­˜ per-utterance ç»“æœ ===
    with open(output_dir / "dev_fun_asr.jsonl", "w", encoding="utf-8") as f:
        for record in per_utt_list:
            f.write(json.dumps(record, ensure_ascii=False) + "\n")

    # === ä¿å­˜æ•´ä½“åˆ†æ•° ===
    score_result = {
        "fun_asr_cer": round(overall_cer, 4),
        "fun_asr_wer": round(overall_wer, 4),
        "num_samples": len(per_utt_list),
        "model_path": MODEL_LOCAL_PATH,
        "language": "zh",
        "itn": True,
        "normalize_rules": "NFKC + lower + remove punctuation + collapse whitespace",
        "wer_tokenization": "jieba for Chinese",
    }

    with open(output_dir / "dev_score_fun_asr.json", "w", encoding="utf-8") as f:
        json.dump(score_result, f, ensure_ascii=False, indent=2)

    print(f"âœ… Overall CER: {overall_cer:.4f}")
    print(f"âœ… Overall WER: {overall_wer:.4f}")
    print(f"ğŸ“Š Processed {len(per_utt_list)} samples")
    print(f"ğŸ“„ Results saved to {output_dir}")


if __name__ == "__main__":
    main()
